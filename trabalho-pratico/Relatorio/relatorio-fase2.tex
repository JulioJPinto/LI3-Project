\documentclass{article}

\usepackage[portuguese]{babel}

\usepackage[a4paper]{geometry}
\usepackage{pbox}
\usepackage{caption, booktabs}
\usepackage{makecell}
\usepackage{cellspace}
\usepackage{lipsum}  


\title{Relatório da Fase 2 - Grupo 03}
\author{Francisco Macedo Ferreira (A100660)\\Júlio José Medeiros Pereira Pinto (A100742)}

\begin{document}  
    \maketitle
    
    \section{Introdução}
    Este relatório tem como intuito abordar a segunda fase do projeto da UC Laboratórios 
    de Informática III do ano letivo 2022/2023.
    Nesta fase como objetivos o trabalho necessitava a implementação de todas as queries
    , de um modo de operação interativo (incluindo menu de interação e um módulo de 
    paginação para apresentação de resultados longos) e evolução de aspetos relacionados
    a modularidade, encapsulamento e qualidade de código. \\
    
    Este relatório irá abranger as decisões tomadas pelo grupo tal como o método de 
    raciocínio para desenvolvimento do mesmo.
    
    \section{Desenvolvimento}
    
    \subsection{Alterações realizadas}
        \subsubsection{Ajustes apontados pelos docentes}
            Após a apresentação da primeira fase do trabalho foram levantados
            alguns pontos por parte dos docentes. Primeiramente foi levantada
            a questão quanto à maneira como o Catálogo, \emph{Catalog}, estava
            estruturado. Originalmente tinhamos os Arrays e Hashtables das 
            estruturas todos juntos, porém foi levantado o ponto que de tal 
            maneira poderiamos estar a quebrar encapsulamento. Assim sendo, 
            decidimos tornar o \emph{Catalog} num struct de catálogos de cada 
            estrutura de dados, catálogos estes opacos ao \emph{Catalog} 
            (será abordado mais abaixo).\\Para além disso, fomos informados 
            pelos professores que não fazia sentido aplicarmos multithreading, 
            \emph{pthreads}, visto que a maneira como o trabalho será testado 
            não permitirá a realização de ações em paralelo, isto pois os 
            programas são testado somente numa thread. Por último, foi nos 
            também aconselhado por um dos professores a transfêrencia de 
            uma estrutura de dados que tinhamos para informações relativamente 
            às rides para a estrutura de dados das rides (será abordado mais 
            abaixo).

        \subsubsection{Ajustes de fator escala (Dataset maior)}
            Da forma como tínhamos o projeto implementado, quando 
            usado o dataset maior, o programa mesmo assim continuava
            a performar dentro dos limites de tempo com grandes 
            margens. As estruturas de dados e estratégias para
            a resolução de queries foram então adequadas, pelo que
            não alteramos a implementação das queries já feitas
            (1, 2, 3, 4 e 5). As previsões de possíveis alterações
            mencionadas na fase 1 não foram necessárias de serem
            implementadas, exceto o \emph{lazy loading} que foi
            útil no modo interativo (será abordado mais abaixo).

        \subsubsection{Otimizações localidade espacial e temporal}
        // TODO: METER ISTO APOS A EXPLICAÇÃO DAS QUERIES
            Apesar da estrutura previeamente implementada permitir a realização
            do trabalho dentro dos limites de tempo com grandes margens, decidimos
            mesmo assim otimizá-lo para além do que o que já tinhamos. Para tal
            alteramos certas estruturas de dados e certos métodos de guardar 
            informações destes de maneira se adequar à melhor a uma melhor localidade 
            temporal e espacial. Decidimos então alterar a maneira como guardamos os 
            nossos condutores no \emph{CatalogDrivers}, trocando a Hashtable presente
            neste (Hashtable para um acesso constante aos condutores pelo ID) por um 
            array onde o índice da posição do Condutor no array é igual ao ID deste 
            mesmo condutor. Ainda mais decidimos também, ao invés de guardar em cada 
            condutor e viagem a cidade, guardar um ID único para cada, de maneira a 
            diminuir o número de \emph{strdups} necessários, assim por consequência, 
            diminuindo também o tempo necessário para a alocação e libertação destes 
            \emph{strdups} tal como o número de bytes necessários para os Condutores e
            Viagens. No mesmo contexto, após alguma discussão, decidimos alterar também
            a maneira como as viagens guardam os utilizadores. Dando a cada utilizador um
            id único permite nos então poupar na quantidade de espaço necessário para as mesmas.
            Ao invés de guardarmos uma string, assim simplesmente, guardamos um inteiro, diminuindo
            o tamanho necessário para as mesmas tal como torna a pesquisa pelo utilizador 
            mais fácil e rápida.

        \subsubsection{Micro-Otimizações}
        // TODO: METER ISTO APOS A EXPLICAÇÃO DAS QUERIES
            De maneira a gerir melhor a memória usada pelo programa decidimos então
            fazer diversas, mas eficazes alterações para a dimensão do projeto.
            Para começar:
            Decidimos alterar a maneira como as datas, a struct \emph{Date},
            funciona. Alteramos então a maneira deste de três ints de 32 bits para um int de 32 bits.
            Pode não parecer muito porém num dataset de 10 mil rides, poupamos cerca de 
            640 000 bits.
            Ainda mais, decidimos também substituir o uso da função \emph{strtol}
            pelas nossa próprias funções de parsing para inteiros.

    \subsection{Pipeline}
        Neste momento o nosso programa funciona da seguinte maneira:
        \begin{itemize}
            \item A nossa main recebe os argumentos, caso não receba nenhum argumento 
            está inicializar o programa no modo intertativo (Command Line Enviroment), 
            que já dentro do programa irá pedir o \emph{dataset} usado para este. Caso 
            esta receba a \emph{path} para o \emph{dataset} e para o \emph{input} o programa 
            será realizado no modo \emph{Batch}.
            \item Após receber o a \emph{path} para o \emph{dataset} o nosso programa da
            \emph{parse} dos dados encontrados em cada CSV. Este ainda mapaeia os mesmos 
            para o catálogo e deixa o catálogo pronto para ser utilizado.
            \item De seguida, dependendo do modo (\emph{Batch} ou Interativo), este irá 
            correr os comandos/\emph{inputs} passados.
            \item No caso do modo \emph{Batch}, este vai ler o ficheiro de \emph{input} 
            e vai fazer cada uma das queries passadas neste. Quando uma query é chamada 
            o programa acede ao nosso \emph{Query Manager} (Gestor de Queries) onde é 
            mapeado para a \emph{Query} respetiva. 
            \item Após este processo a query será calculada e será impressa para uma struct
            \emph{OutuputWriter} onde guardamos o resultado. Caso este quando chega ao mesmo 
            dependendo do modo, \emph{Batch} ou Interativo este será impresso para um ficheiro
            de \emph{output} ou para o terminal. No modo interativo caso seja maior que o 
            \emph{PAGE-SIZE} definido (10 linhas) este passará a modo de paginação.
            \item 
            
        \end{itemize}
    \subsection{Queries Implementadas}
        Para a segunda fase do trabalho foram aplicadas todas as queries em falta
        (Queries 1 a 5 realizadas na fase anterior). Foram implementadas as queries 6, 7, 8 e 9.
        A implementação das queries anteriores não foi alterada, apenas foi otimizado
        algumas partes do catálogo para que o indexamento dos dados fosse mais rápido.
        \subsubsection{Query 6}
            De maneira a conseguirmos calcular o preço médio dentro de uma data usamos
            o \emph{array} de rides que está ordenado por data. Com ele fazemos \emph{binary search} para
            encontrar a data do começo (ou a próxima maior caso não exista) e percorremos o array, 
            linearmente, até a segunda data, fazendo média dos preços das viagens. O preço
            de cada viagem foi calculado e guardado na ride durante a inserção nos catálogos para evitar
            \emph{lookups} às informações do condutor quando necessário.
        \subsubsection{Query 7}
            Para a query 7 tivemos que recorrer a uma nova estrutura de dados separado dos condutores: \emph{DriverCityInfo}. 
            Essa estrutura de dados guarda o score de um condutor numa cidade específica.
            Conforme a inserção de rides no catálogo, vamos somando o score do condutor daquela ride
            a um valor acumulado dentro da tal estrutura de dados. Para cada cidade, existe um array de \emph{DriverCityInfo} e
            uma \emph{hashtable} temporária para fazer com que na inserção não
            seja necessário percorrer o array inteiro para encontrar (ou ver que ainda não existe)
            o \emph{DriverCityInfo} onde queremos somar o score de tal ride. 
            Quando surge uma nova cidade, é criado um novo \emph{array} e uma nova \emph{hashtable} temporária.
            Após a inserção de todas as rides, os \emph{hashtables} são libertados e cada array é ordenado por score.
            
            Não foi possível, por exemplo, guardar um array na própria estrutura de dados do condutor
            porque não sabemos a quantidade de cidades que existem no dataset até o lermos por completo,
            pelo que teríamos que fazer \emph{reallocs} muito constantes, o que não é de todo eficiente.

            Assim, com esta implementação, conseguimos fazer com que cidades sejam lidas e adicionadas dinâmicamente
            de forma eficiente.

            Quando a query é chamada, simplesmente pegamos nos primeiros \emph{n} elementos do array
            da cidade pedida e imprimimos o resultado formatado, visto que os arrays estão ordenados por score.
        \subsubsection{Query 8}
            TODO
        \subsubsection{Query 9}
            TODO
    \subsection{Estruturas de Dados}
        \subsubsection{Catalógo}
            TODO
        \subsubsection{\emph{Lazy}}
            De maneira a tornar o programa mais eficiente decidimos criar uma
            estrutura de dados já presente ou semelhante em outras linguagens de programação.
            Para otimizar o tempo de carregamento dos dados, implementamos o '\emph{Lazy}' que é uma
            estrutura que permite aplicar uma função a um valor quando este é requisitado.

            A função e o valor são passados como parametros na criação da estrutura.

            A estrutura foi implementada da forma mais genérica possível, de forma a que
            possa ser usada para qualquer tipo de dados.

            Isto permite então que, por exemplo, várias funções de \emph{sort} sejam aplicadas
            apenas quando necessário, pelo que quando uma query nunca é chamada, as estruturas necessárias
            não sejam indexadas desnecessariamente. Também torna o carregamento do modo interativo
            mais leve. 

            Este \emph{lazy sorting} é feito por defeito, mas para dar escolha ao utilizador,
            pode ser desativado passando \emph{flag} \emph{--lazy-loading=false}
            como argumento ao programa (esta \emph{flag} pode estar em qualquer
            posição não interferindo com os datasets passados como argumento).
        \subsubsection{\emph{Program}}
            Visto que o nosso modo interativo decidimos fazer um \emph{Command Line Enviorment} tivemos
            a necessidade de criar a struct \emph{program}. Nesta struct guardamos os diversos estados e
            modos que o programa está a ser corrido. Tal como todas as flags passadas a este, o Catálogo 
            geral, o valor da query que estamos a passar e um booleano que dita se devemos sair do programa.
            Desta maneira também conseguimos controlar se corremos o trabalho em \emph{batch mode} ou no 
            modo interativo, assim garantindo que conseguimos realizá-lo de ambas as maneiras.
    \subsection{Modo Interativo}
            Como sugerido por alguns professores, ao invés de utilizarmos \emph{ncurses} ou outra 
            biblioteca externa de maneira a fazer uma TUI (Terminal User Interface), após diversa 
            discussão, decidimos avançar com um modo interativo no estilo de um \emph{Command Line 
            Enviorment}. Para isso usamos bibliotecas como a \emph{readline/readline} e 
            \emph{readline/history}. 
        \subsubsection{Lista de Comandos}
            No modo interativo utilizamos diferentes comandos para a realização das necessidades do
            utilizador. Primeiramente temos um comando help, que lista todos os comandos possíveis 
            do programa. O utilizador de maneira a correr as queries pode chamar um ficheiro, usando 
            o comando \emph{file}, como também pode as escrever diretamente na linha de comando. Enquanto 
            que ao chamar o file, dará output para novos ficheiros, ao escrever diretamente na linha de 
            comando o resultado será exposto no terminal. Para além destes comandos ainda temos o comando 
            \emph{reload} que permite ao utilizador inserir um novo \emph{dataset}, caso este mude 
            durante a utilização do programa ou caso o utlizado pretenda utilizar um \emph{dataset}
            diferente sem ter que sair do programa e também temos o comando \emph{clear}, que tal como
            o nome indica, impa o terminal. Por último temos o comando \emph{exit} de maneira a sair do 
            programa.
        \subsubsection{Histórico de Comandos}
            Através da utilização da biblioteca \emph{readline/history} decidimos também implementar um 
            histórico de comandos. Desta maneira caso o utilizador necessite de reutilizar um comando 
            anteriror não precisa de se preocupar, visto que os comandos previamente introduzidos são 
            guardados em memória.
        \subsubsection{Paginação}
            Como em certas queries (Ex: Query 2 e 3) existe a possibilidade de termos um output muito 
            grande de linhas, tal como pedido no enunciado, implementamos um sistema de paginação para
            essas situações. No nosso sistema de paginação conseguimos percorrer o \emph{output} de duas 
            maneiras diferentes. Conseguimos percorrer este página a página, avançando ou retrocedendo de
            página, como também conseguimos simplesmente dizer a página que pretendemos e esta será impressa 
            no terminal. De ambas as maneiras a página anterior será apagada do terminal.
    \subsection{Testes Unitários}
        \subsubsection{Actions do Github}
        De maneira a conseguirmos garantir que o código presente no nosso repositório passaria sempre os
        testes dos professores, decidimos criar algumas Actions para o mesmo. Assim mesmo que não
        conseguissemos testar na nossa máquina local, saberiamos caso o projeto tivesse \emph{memory
        leaks} ou falhas nos testes, seriamos alertados, tal como nos seria demonstrado onde errou ou a o
        output do valgrind.
    \subsection{\emph{CSV Generator}}
    \section{Testes de Performance}
        \begin{table}[hbt!]
            \centering
            \begin{tabular}{|*{3}{c|}}
                \hline
                & \thead{PC 1}&\thead{PC 2}\\
                \hline
                CPU        & M1 Pro 8-core (6 perf. e 2 ef.) & Intel i7-8550U 4-core \\
                RAM        & 16GB LPDDR5                     & 8GB DDR4 2400MHz \\
                Disco      & 500GB NVME                      & 500GB NVME \\
                OS         & MacOS Ventura 13.0.1            & ArcoLinux Kernel 6.0.9 \\
                Compilador & Clang 15.0.5 (ARM64)            & GCC 12.2.0 \\
                \hline
            \end{tabular}
            \caption{Especificações dos PCs}
        \end{table}
         

        \begin{table}[hbt!]
                \centering
                \begin{tabular}{|*{4}{c|}}
                    \hline
                    & \thead{PC 1}&\thead{PC 2}&\thead{Testes dos Professores}\\
                    \hline
                    Loading de ficheiros                  & 767.1ms & 1466.1ms & 1427.4ms \\
                    Regular Dataset (with invalid entries)   & 8.0ms   & 23.3ms & 32.7ms \\
                    Regular Dataset (without invalid entries) & 14.1ms  & 45.2ms &  66.5 ms \\
                    \hline
                \end{tabular}
                \caption{Tempos de execução para o Regular Dataset}

                \centering
                \begin{tabular}{|*{4}{c|}}
                    \hline
                    & \thead{PC 1}&\thead{PC 2}&\thead{Testes dos Professores}\\
                    \hline
                    Loading de ficheiros                  & 767.1ms & 1466.1ms & 1427.4ms \\
                    Large Dataset (with invalid entries)   & 8.0ms   & 23.3ms & 32.7ms \\
                    Large Dataset (without invalid entries) & 14.1ms  & 45.2ms &  66.5 ms \\
                    \hline
                \end{tabular}
                \caption{Tempos de execução para o Large Dataset}
            \end{table} 

        


    

\end{document}
