\documentclass{article}

\usepackage[portuguese]{babel}

\usepackage[a4paper]{geometry}
\usepackage{pbox}
\usepackage{caption, booktabs}
\usepackage{makecell}
\usepackage{cellspace}
\usepackage{lipsum}  


\title{Relatório da Fase 1 - Grupo 03}
\author{Francisco Macedo Ferreira (A100660)\\Hugo António Gomes Ramos (A100644)\\Júlio José Medeiros Pereira Pinto (A100742)}

% Document
\begin{document}

    \maketitle

    \section{Introdução}

    Este relatório tem como intuito abordar a primeira fase do projeto da UC Laboratórios 
    de Informática III do ano letivo 2022/2023.
    Nesta fase como objetivos o trabalho necessitava a implementação de \emph{parsing} dos
    dados de entrada, funcionar através do modo de operação \emph{batch}, 
    realizar pelo menos 3 das 9 \emph{queries} considerando que o 
    tamanho dos ficheiros de entrada 
    (\emph{users.csv, drivers.csv} e \emph{rides.csv}), terá 100.000, 10.000 e 
    1.000.000 linhas, respetivamente. Ainda mais, no projeto, em geral, existe 
    uma necessidade do uso de conceitos de encapsulamento e modularidade.
    \\
    \\Este relatório irá abrangir as decisões tomadas pelo grupo tal como o método de raciocínio para desenvolvimento do mesmo.
    

    \section{Desenvolvimento}

        \subsection{Pipeline atual}
            Neste momento a nossa pipeline funciona da seguinte maneira: 
            \begin{itemize}
                \item Abre-se os ficheiros do dataset passados como parámetro do 
                programa (\emph{drivers.csv, users.csv, rides.csv})
                \item Cada linha desses ficheiros é passada para um parser genérico
                com informações de como interpertar essa linha e o que fazer com
                a estrutura \emph{parsed}.
                \begin{itemize}
                    \item A informação de como interpretar a linha é um pointer para
                    a função de \emph{parse\_line\_user}, \emph{parse\_line\_driver} ou \emph{parse\_line\_driver},
                    uma em cada ficheiro de cada estrutura.
                    \item A informação de o que fazer com a estrutura \emph{parsed} é um pointer para
                    a função de \emph{register\_user}, \emph{register\_driver} ou \emph{register\_ride}
                    no \emph{catalog.c}.
                \end{itemize}
                \item Ao finalizar a leitura, \emph{parsing} e indexamento de
                todas as linhas no catálogo, este irá ordenar as \emph{arrays} 
                dentro do catálogo da maneira mais útil para a rápida execução das 
                queries.
                \item Depois do catálogo pronto, lemos o ficheiro de input.
                Cada linha, em conjunto com o ficheiro de output correspondente criado,
                é passado para o \emph{query\_manager.c}, um controlador
                de queries, que irá verificar qual a query que está a ser pedida
                e chamar a função correspondente, separando a linha por espaços
                para a fácil interpretação dos parâmetros.
                \item Por fim, os ficheiros são fechados, a memória é libertada 
                e o programa termina.
            \end{itemize}
        \subsection{Estratégias Seguidas nas Queries}
            Para a primeira fase do trabalho decidimos implementar as bases do 
            projeto, como o parser e definir as estruturas dos dados que 
            utilizaremos ao longo do projeto (Como o catálogo para guardar os 
            dados e os \emph{users, drivers} e \emph{rides}). Foram 
            implementadas as \emph{queries} 1, 2, 3, 4 e 5. 
            
        \subsubsection{Query 1}
            Para acesso rápido a perfis pelo \emph{id's} de condutores ou 
            \emph{username's} de utilizadores foram utilizadas duas 
            \emph{HashTables} (uma para indexar os perfis de condutores e outra 
            para perfis de utilizadores) com \emph{key id e username} e 
            \emph{value Driver* e User*} respetivamente. Esses \emph{HashTables}
            são populados conforme a leitura dos ficheiros {.csv} e informações
            como número de viagens, soma total de avaliações (para poder ser 
            calculado a média), total gasto/auferido eram calculados e guardados 
            na estrutura de dados dos utilizadores e dos condutores\footnote{Pode 
            ser uma possível quebra de encapsulamento. Ainda aguardamos a resposta
            do docente sobre esse quesito.}. A decisão de buscar informações de
            utilizadores ou condutores é feita pela confirmação se o primeiro 
            argumento da query é um número ou não: se for um número busca-se por
            condutores (\emph{id}), se não busca-se por utilizadores (\emph{username}).
            \\
            \\Com isto é possível um acesso em tempo constante a essas
            informações, com o custo da leitura dos ficheiros ser um pouco maior
            (devido ao calculo necessário de \emph{hashes} para cada \emph{key} 
            e não só). Como na segunda fase o número de perfis irá aumentar
            exponencialmente e é esperado múltiplos acessos a estas informações, 
            seja de várias queries destas ou do modo interativo ainda a 
            implementar, o custo de leitura dos ficheiros superior é muito 
            justificado.
        \subsubsection{Query 2}
            Na query 2, para rápido acesso aos condutores com maior média foi 
            feito \emph{sorting} da \emph{array} (presente no catálogo) de 
            condutores, conforme a sua média, no fim da leitura dos ficheiros.
            Isto poderá ser otimizado a fazer com que o \emph{sorting} seja
            \emph{lazy} (será abordado este tópico mais tarde).
            Durante a execução da query basta obter os N primeiros 
            condutores da \emph{array} e temos a execução em práticamente em
            tempo constante (agora é copiado os N elementos para uma array, mas
            poderá ser otimizado).
        \subsubsection{Query 3}
            Para a query 3, tal como na query 2, foi feito \emph{sorting} da
            \emph{array} (presente no catálogo) de utilizadores no fim da leitura
            dos ficheiros, de maneira a otimizar o acesso aos users com maior 
            distância total percorrida.
            Por isso, durante a execução desta query o tempo de execução será praticamente
            constante (também tendo em conta a cópia dos N elementos para uma array).
            Tal como na query 2, o tópico de \emph{lazy sorting} poderá ser aplicado
            da mesma maneira.
        \subsubsection{Query 4}
            Nesta query, o preço médio das viagens numa determinada cidade é 
            calculada (em tempo linear conforme o número de viagens por cidade)
            durante a execução da query. Durante a leitura das viagens,
            é inserido a viagem conforme a sua cidade numa 
            \emph{HashTable (key: cidade, value: Array de Ride*)}. 
            O preço médio não é pré-calculado, pois o cálculo desta é 
            relativamente rápido devido às viagens já estarem separadas por cidade
            e é expectável que só se aceda a este valor uma vez, por isso
            guardá-lo será desnecessário.
            Esta \emph{HashTable} já existe devido à query 7 que necessitará de
            acesso rápido a viagens conforme a sua cidade. 
            \\
            \\Futuramente, conforme a expansão do dataset, esta implementação 
            poderá ter que ser reformulada, por causa do cálculo em execução mas
            para já tivemos bom desempenho com a atual.
        
        \subsubsection{Query 5}
            \newcommand{\param}[1]{$<${#1}$>$}
            Já na query 5, no fim da leitura das viagens é feito \emph{sorting}
            das viagens pela sua data, por ordem crescente. Com isto, assumindo 
            que \param{data A} e \param{data B} são os argumentos da query, 
            basta aceder ao primeiro elemento a partir do qual \param{data A} é 
            menor ou igual do que a data desse elemento. A partir daí, podemos
            percorrer a lista até encontrar uma viagem que a sua data seja
            maior que \param{data B}, acumulando o preço das viagens para no fim
            calcular a sua média. O tal primeiro elemento é encontrado com
            uma implementação semelhante à \textbf{std::lower\_bound} de \emph{C++},
            usando \emph{binary search}. Isto é possível devido à lista estar
            organizada pela data das viagens.
            \\
            \\Para evitar percorrer a lista, podia ter sido pré-calculado uma \emph{array}
            em que cada indíce tinha o somatório de preços para trás desse indíce
            e o preço médio era calculado subtraindo o \emph{upper\_bound}
            com o \emph{lower\_bound} do \emph{range} das datas e dividindo pelo 
            número de elementos entre eles. Essa ideia foi rápidamente descartada
            devido às datas dos argumentos serem relativamente perto, portanto
            são poucas as viagens a iterar. Esta solução também iria aumentar 
            consideravelmente o tempo de leitura dos ficheiros.

        \newpage
        \subsection{Análise de desempenho}
            Comparando o desempenho da execução das queries 1, 2, 3, 4 e 5 para 
            os ficheiros de input do conjunto de testes expandido das pastas 
            \emph{tests\_1} e \emph{tests\_2} (excluindo obviamente as queries não 
            implementadas) temos na Tabela 2 os resultados conforme as 
            especificações dos computadores na Tabela 1. Ainda não existe um
            \emph{standard} para a medição de desempenho dos programas, por isso,
            medimos da seguinte forma:

            \begin{itemize}
                \item O programa foi compilado com as flags \emph{-O3 -flto -funroll-loops -march=native}.
                \item \textbf{Loading time} é o tempo de leitura, \emph{parse} e indexamento dos 
                ficheiros de input (incluindo o tempo de \emph{sorting} no fim).
                Para já o loading é independente das queries executadas.
                \item \textbf{Query time} é o tempo de execução de todas as queries no ficheiro,
                incluindo a escrita do output nos ficheiros.
                \item Não são considerados tempos de \emph{free} de memória (no fim da execução
                do programa) em nenhum dos tempos.
                \item O resultado é uma média de 3 execuções, após uma primeira execução de aquecimento. 
                \item O tempo foi medido no código com o utilitário \emph{GTimer} do \emph{GLib}.
            \end{itemize}
            
            \begin{table}[hbt!]
                \centering
                \begin{tabular}{|*{4}{c|}}
                    \hline
                    & \thead{PC 1}&\thead{PC 2}&\thead{PC 3}\\
                    \hline
                    CPU        & M1 Pro 8-core (6 perf. e 2 ef.) & Intel i7-8550U 8-core         & Intel i7-1165G7 \\
                    RAM        & 16GB LPDDR5                     & 8GB DDR4 2400MHz              & 16GB RAM DDR4 3200 MHz \\
                    Disco      & 500GB NVME                      & 500GB NVME                    & 1TB SSD \\
                    OS         & MacOS Ventura 13.0.1            & ArcoLinux Kernel 6.0.9-arch-1 & Windows 11 WSL 1.0 (Ubuntu 20.04) \\
                    Compilador & Clang 15.0.5 (ARM64)            & GCC 12.2.0                    & GCC 9.2.0 \\
                    \hline
                \end{tabular}
                \caption{Performances em diferentes PCs}
            \end{table}
            
            \begin{table}[hbt!]
                \centering
                \begin{tabular}{|*{4}{c|}}
                    \hline
                    & \thead{PC 1}&\thead{PC 2}&\thead{PC 3}\\
                    \hline
                    Loading de ficheiros                  & 767.1ms & 1466.1ms & 1427.4ms \\
                    Execução de 13 queries (tests\_1.txt)    & 8.0ms   & 23.3ms & 32.7ms \\
                    Execução de 29 queries (tests\_2.txt) & 14.1ms  & 45.2ms &  66.5 ms \\
                    \hline
                \end{tabular}
                \caption{Tempos de execução em diferentes PCs}
            \end{table}            
            
            Sobre o uso de memória, o programa usa, em pico, próximo de um total de 168 MB.

        \subsection{Possíveis otimizações e futuras limitações}
        Como podemos ver na Tabela 2, o tempo de execução das queries é muito
        pequeno, comparado com o tempo de loading dos ficheiros.
        Após alguns simples testes, chegamos à conclusão que uma parte 
        significativa do tempo de loading é do \emph{parsing} das linhas
        das estruturas de dados e outra parte é da inserção, \emph{sorting} 
        e indexamento das viagens, condutores e utilizadores nas estruturas
        adequadas. Para melhorar este tempo, podemos implementar multi-threading
        na leitura dos ficheiros de condutores e utilizadores, pois não há
        dependências entre eles, e talvez rever a forma como as estruturas
        estão a ser \emph{parsed}. Como as número de viagens, condutores e
        utilizadores ainda vai aumentar exponencialmente na segunda fase
        do projeto, será realmente necessário explorar possíveis melhorias
        nesta parte.
        \\
        \\A parte positiva é que parece que as escolhas de implementações
        das \emph{queries} foram excelentes, pois o tempo de execução é
        super rápido. Ainda assim, podemos melhorar a performance das queries
        com, por exemplo, as otimizações de \emph{lazy sorting} referidas nas explicações
        das implementações das \emph{queries}. Este \emph{lazy sorting} pode
        também aliviar o tempo de loading dos ficheiros, já que este só será
        feito quando necessário, ou seja, quando uma \emph{query} for executada. 
        \\
        \\Sobre o uso de memória, também estamos confiantes para a segunda fase
        já que para o dataset atual de 93.8 MB, apesar do nosso programa usar
        1.8 vezes mais (168 MB), ainda conseguimos fazer várias otimizações nas 
        estruturas de dados para a reduzir. Se esse rácio se mantiver, ainda podemos
        lidar com um dataset de 1 GB sem atingir o limite estipulado de 2 GB de 
        uso de memória.
        
    \section{Conclusão}
        Para concluir, acreditamos que o desenvolvimento desta primeira fase foi
        muito satisfatória. Consolidamos os nosso conhecimentos de C com 
        conhecimentos mais avançados relacionadas a performance, gestão de memória, 
        encapsulamento e modularidade. 
        \\Tópicos como o uso de \emph{getters com clone}
        e o \emph{encapsulamento de estruturas} fizeram um pouco de confusão a 
        serem aplicados numa linguagem de tão baixo nível sem suporte a objetos:
        o código ficou  mais verboso e menos performante do que se não houvesse
        essa "restrição".
        \\Apesar de tudo, a nosso ver ainda existe 
        espaço para melhorias nestes conceitos e pretendemos 
        desenvolvê-los a um nível ainda mais avançado do que
        os apresentados na próxima fase do trabalho.
\end{document}